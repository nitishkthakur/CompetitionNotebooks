{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/janatahack-customer-segmentation/Test.csv\n",
      "/kaggle/input/janatahack-customer-segmentation/sample_submission.csv\n",
      "/kaggle/input/janatahack-customer-segmentation/Train.csv\n",
      "Collecting rfpimp\r\n",
      "  Downloading rfpimp-1.3.5.tar.gz (10 kB)\r\n",
      "Collecting stratx>=0.2\r\n",
      "  Downloading stratx-0.4.1.tar.gz (160 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 160 kB 5.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rfpimp) (1.18.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from rfpimp) (1.0.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from rfpimp) (0.23.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from rfpimp) (3.2.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stratx>=0.2->rfpimp) (1.4.1)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from stratx>=0.2->rfpimp) (0.48.0)\r\n",
      "Collecting colour\r\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->rfpimp) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->rfpimp) (2019.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->rfpimp) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->rfpimp) (0.14.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (2.4.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->rfpimp) (0.10.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->stratx>=0.2->rfpimp) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba->stratx>=0.2->rfpimp) (0.31.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->rfpimp) (1.14.0)\r\n",
      "Building wheels for collected packages: rfpimp, stratx\r\n",
      "  Building wheel for rfpimp (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for rfpimp: filename=rfpimp-1.3.5-py3-none-any.whl size=10257 sha256=0390d74993f42c77f39a611e04c0363567194def691c6de56fce34cb786452c3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/88/ae/4e8850abc5088fd7e50cc7f869450d6085a0ec6d245adf8874\r\n",
      "  Building wheel for stratx (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for stratx: filename=stratx-0.4.1-py3-none-any.whl size=35079 sha256=cac1b69c90bc8caa4f6614daa22d922d0b78f81ad4b4445e33158bb166712f93\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/85/01/fa1a3072052c9b027e3c40654b5dc8a488be8afc07442f39e0\r\n",
      "Successfully built rfpimp stratx\r\n",
      "Installing collected packages: colour, stratx, rfpimp\r\n",
      "Successfully installed colour-0.1.5 rfpimp-1.3.5 stratx-0.4.1\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import cluster, preprocessing, linear_model, tree, model_selection, feature_selection\n",
    "from sklearn import base, ensemble, decomposition, metrics, pipeline, datasets, impute\n",
    "from skopt import gp_minimize, space, gbrt_minimize, dummy_minimize, forest_minimize\n",
    "from functools import partial\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn import ensemble, preprocessing, tree, model_selection, feature_selection, pipeline, metrics, svm\n",
    "from imblearn import under_sampling, over_sampling, combine\n",
    "from imblearn import pipeline as imb_pipeline\n",
    "from imblearn import ensemble as imb_ensemble\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "!pip install rfpimp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/janatahack-customer-segmentation/Train.csv')\n",
    "test = pd.read_csv('/kaggle/input/janatahack-customer-segmentation/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    2268\n",
       "A    1972\n",
       "C    1970\n",
       "B    1858\n",
       "Name: Segmentation, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View target balance/Imbalance\n",
    "train['Segmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "rev_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No  Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes    Engineer              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label Encode and preprocess\n",
    "train_copy  = train.copy()\n",
    "test_copy = test.copy()\n",
    "train_copy['tr'] = 1\n",
    "test_copy['tr'] = 0\n",
    "\n",
    "appended = pd.concat([train_copy, test_copy], axis = 0)\n",
    "\n",
    "cat_cols = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "label_enc = {}\n",
    "for col in cat_cols:\n",
    "    appended[col] = appended[col].astype(str)\n",
    "    enc = preprocessing.LabelEncoder().fit(appended[col])\n",
    "    appended[col] = enc.transform(appended[col])\n",
    "    label_enc[col] = enc\n",
    "\n",
    "cats = ['Gender', 'Ever_Married','Graduated','Profession','Spending_Score',\n",
    "'Var_1']\n",
    "appended = pd.get_dummies(appended, columns = cats)\n",
    "##################### create features from ID column ##############\n",
    "def id_features(data):\n",
    "    df = data.copy()\n",
    "    df['week'] = df['ID']%7\n",
    "    df['month'] = df['ID']%30\n",
    "    df['year'] = df['ID']%365\n",
    "    df['num_weeks'] = df['ID']//7\n",
    "    df['num_year'] = df['ID']//365\n",
    "    df['num_quarter'] = df['ID']//90\n",
    "    df['quarter'] = df['ID']%90\n",
    "    df['num_days'] = df['ID'].values - 458982\n",
    "    df['num_weeks_2'] = (df['ID'].values - 458982)//7\n",
    "    df['num_months_2'] = (df['ID'].values - 458982)//30\n",
    "\n",
    "    return df\n",
    "def id_features(data):\n",
    "    df = data.copy()\n",
    "    df['week'] = df['ID']%7\n",
    "    df['month'] = df['ID']%30\n",
    "    df['year'] = df['ID']%365\n",
    "    df['quarter'] = df['ID']%90\n",
    "\n",
    "\n",
    "    return df\n",
    "appended = id_features(appended)\n",
    "#appended = pd.get_dummies(appended, columns = cat_cols)\n",
    "train_copy = appended.loc[appended['tr'] == 1]\n",
    "test_copy = appended.loc[appended['tr'] == 0]\n",
    "Xcols = appended.drop(['Segmentation', 'tr'], axis = 1).columns\n",
    "'''Xcols = ['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1']'''\n",
    "ycol = 'Segmentation'\n",
    "\n",
    "X = train_copy[Xcols]\n",
    "y = train_copy[ycol]\n",
    "\n",
    "Xtest = test_copy[Xcols]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tune Hyperparameters - skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 13.9384\n",
      "Function value obtained: -0.5265\n",
      "Current minimum: -0.5265\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 41.2777\n",
      "Function value obtained: -0.5346\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 22.2430\n",
      "Function value obtained: -0.5275\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 57.4814\n",
      "Function value obtained: -0.5306\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 16.6387\n",
      "Function value obtained: -0.5316\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 46.7405\n",
      "Function value obtained: -0.5288\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 27.9907\n",
      "Function value obtained: -0.5130\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 14.0165\n",
      "Function value obtained: -0.5283\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 46.1671\n",
      "Function value obtained: -0.5289\n",
      "Current minimum: -0.5346\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 26.5539\n",
      "Function value obtained: -0.4856\n",
      "Current minimum: -0.5346\n"
     ]
    }
   ],
   "source": [
    "############ Tune Random Forest\n",
    "def optimize_sk(params, param_names, X, y, scoring, estimator, cv = model_selection.StratifiedKFold(n_splits = 5)):\n",
    "    '''params: list of param values\n",
    "    param_names: param names\n",
    "    x: training exogs\n",
    "    y: training endogs\n",
    "    return: negative metric after k fold validation'''\n",
    "\n",
    "    params = dict(zip(param_names, params))\n",
    "\n",
    "    # Initialize the model\n",
    "    model = estimator(**params)\n",
    "\n",
    "    kf = cv\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        # Split Data\n",
    "        X_train, y_train = np.array(X)[train_index, :], y[train_index]\n",
    "        X_test, y_test = np.array(X)[test_index, :], y[test_index]\n",
    "\n",
    "        # Fit model\n",
    "        im = impute.KNNImputer().fit(X_train)\n",
    "        X_train = im.transform(X_train)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model\n",
    "        preds = model.predict(im.transform(X_test))\n",
    "        scores.append(scoring(y_test, preds))\n",
    "\n",
    "    return -np.mean(scores)\n",
    "\n",
    "# Scoring\n",
    "def f1_score(y_true, y_pred):\n",
    "    return metrics.f1_score(y_true, y_pred, average = 'macro')\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Parameter Space\n",
    "param_space = [\n",
    "    space.Integer(100, 1000, name = 'n_estimators'),\n",
    "    space.Integer(2, 25, name = 'max_depth'),\n",
    "    space.Real(0, 1, name = 'max_features'),\n",
    "    space.Integer(2, 25, name = 'min_samples_leaf'),\n",
    "    space.Categorical(['gini', 'entropy'], name = 'criterion'),\n",
    "    space.Categorical([None, 'balanced', 'balanced_subsample'], name = 'class_weight'),\n",
    "    space.Categorical([True, False], name = 'bootstrap')\n",
    "]\n",
    "\n",
    "# Param names\n",
    "names = ['n_estimators', 'max_depth', 'max_features', 'min_samples_leaf', 'criterion', 'class_weight', 'bootstrap']\n",
    "\n",
    "cat_cols =  ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1', 'ID']\n",
    "cat_cols =  ['Var_1']\n",
    "\n",
    "# Define objective - reformat it in terms of what is required for skopt\n",
    "objective_optimization = partial(optimize_sk, param_names = names, X = X, y = y, \n",
    "                                scoring = accuracy, estimator = partial(ensemble.RandomForestClassifier, n_jobs = -1, random_state = 0))\n",
    "\n",
    "# Perform Optimization\n",
    "#gbrt_minimize, dummy_minimize, forest_minimize\n",
    "'''skopt_optimization = gp_minimize(func = objective_optimization, \n",
    "                                dimensions = param_space, n_calls = 10, n_random_starts = 10, \n",
    "                                x0 = None, y0 = None, random_state = 10, \n",
    "                                verbose = 10)'''\n",
    "skopt_optimization = dummy_minimize(func = objective_optimization, \n",
    "                                dimensions = param_space, n_calls = 10,\n",
    "                                x0 = None, y0 = None, random_state = 10, \n",
    "                                verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.make_pipeline(impute.KNNImputer(), \n",
    "                               ensemble.RandomForestClassifier(**dict(zip(names, skopt_optimization.x)), \n",
    "                                                               n_jobs = -1, random_state = 0)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 981,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 0.26556612677209707,\n",
       " 'min_samples_leaf': 12,\n",
       " 'criterion': 'gini',\n",
       " 'class_weight': 'balanced_subsample',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(names, skopt_optimization.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ensemble and perform hand Tuning. Tuning models by hand gave me better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb = cb.CatBoostClassifier( verbose = False)\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators = 1000, min_samples_in_leaf = 10, learning_rate = .02, \n",
    "                          feature_fraction = .8, max_depth = 8)\n",
    "\n",
    "# Soft Voting Classifier\n",
    "model_voting = ensemble.VotingClassifier([('catboost', model_cb), ('lightgbm', model_lgb)], \n",
    "                                         voting = 'soft').fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# The best pipelines so far:\n",
    "### * kNN Imputation + RandomForest\n",
    "### * Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .94\n",
    "model4 = pipeline.make_pipeline(impute.KNNImputer(n_neighbors = 10), ensemble.RandomForestClassifier(class_weight = 'balanced_subsample',\n",
    "                    n_estimators = 200, max_depth = 20, criterion = 'entropy', max_features = .8, oob_score = True, random_state = 0)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .94\n",
    "model2 = lgb.LGBMClassifier(n_estimators=300, max_features = .85, max_depth = 15, learning_rate = 1.1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <td>0.0622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_Experience</th>\n",
       "      <td>0.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_Size</th>\n",
       "      <td>0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_0</th>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_5</th>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_8</th>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_2</th>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_3</th>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_2</th>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender_0</th>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_3</th>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_4</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_0</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ever_Married_2</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_7</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_6</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_5</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_4</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_2</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1_0</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_0</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending_Score_0</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_9</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_7</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated_2</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession_6</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Importance\n",
       "Feature                     \n",
       "Age                   0.1734\n",
       "ID                    0.1438\n",
       "year                  0.1062\n",
       "quarter               0.0622\n",
       "month                 0.0328\n",
       "Work_Experience       0.0290\n",
       "Family_Size           0.0270\n",
       "Profession_0          0.0150\n",
       "Profession_5          0.0132\n",
       "week                  0.0104\n",
       "Profession_8          0.0016\n",
       "Spending_Score_2      0.0012\n",
       "Profession_3          0.0006\n",
       "Profession_2          0.0004\n",
       "Gender_0              0.0004\n",
       "Var_1_3               0.0002\n",
       "Profession_1          0.0000\n",
       "Profession_4          0.0000\n",
       "Ever_Married_0        0.0000\n",
       "Ever_Married_1        0.0000\n",
       "Ever_Married_2        0.0000\n",
       "Var_1_7               0.0000\n",
       "Var_1_6               0.0000\n",
       "Var_1_5               0.0000\n",
       "Var_1_4               0.0000\n",
       "Var_1_2               0.0000\n",
       "Var_1_1               0.0000\n",
       "Var_1_0               0.0000\n",
       "Graduated_0           0.0000\n",
       "Spending_Score_1      0.0000\n",
       "Spending_Score_0      0.0000\n",
       "Profession_9          0.0000\n",
       "Gender_1              0.0000\n",
       "Profession_7          0.0000\n",
       "Graduated_1           0.0000\n",
       "Graduated_2           0.0000\n",
       "Profession_6          0.0000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### View Feature importance  -  Using Permutation Importance\n",
    "import rfpimp\n",
    "\n",
    "imp = rfpimp.importances(model2, X, y)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['ID'] = test['ID'].values\n",
    "pred['Segmentation'] = pd.Series(model2.predict(Xtest))\n",
    "pred.to_csv('Seg.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
